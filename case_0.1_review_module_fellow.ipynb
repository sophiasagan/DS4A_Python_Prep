{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f36ba51edd0dd950e2ba8f9621e3fcc9",
     "grade": false,
     "grade_id": "cell-43ad9dbc15f6ee1c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Review module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "16f632a1834fca2ebb26f2c77d0c2773",
     "grade": false,
     "grade_id": "cell-d82cb3096a8518c2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Throughout this pre-foundational program, you will complete several auto-graded mini-homeworks designed to test your understanding of the previous cases. This is the first of those mini-homeworks, covering case 0.1.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "For this review module, the exercises will require you to uncomment lines of code. In order to complete this part, we recommend you follow these instructions:\n",
    "\n",
    "1. Complete the functions provided to you in this notebook, but do **not** change the name of the function or the name(s) of the argument(s). If you do that, the autograder will fail and you will not receive any points.\n",
    "2. Run all the function-definition cells before you run the testing cells. The functions must exist before they are graded!\n",
    "3. Read the function docstrings carefully. They contain additional information about how the code should look (a [docstring](https://www.datacamp.com/community/tutorials/docstrings-python) is the stuff that comes between the triple quotes).\n",
    "\n",
    "**How do functions work?**\n",
    "\n",
    "You probably haven't seen Python functions before, but don't worry, we will be covering them in a future case. For now, the main things you need to know are:\n",
    "\n",
    "1. Write your code as you would usually do, only this time write it inside the function just below the `### Your code here` comment.\n",
    "2. Functions usually start with the `def` keyword and end with `return some_variable` . Don't modify any of these. If you just write your code as we explained above, you'll be good.\n",
    "3. The code you write should be indented.\n",
    "4. The docstring lets you know the name of the variable you will have to return. The `return` statement gives you this information as well. So if, for instance, the function says `return fancy_dict` you must make sure that the variable that you define as your result is also called `fancy_dict`.\n",
    "\n",
    "Here are a couple of already-solved example questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "433b27008025de5ae7a152baf062f730",
     "grade": false,
     "grade_id": "cell-627a3738ce1a6703",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Example 1\n",
    "\n",
    "What is the coolest animal in the world? (Remember, you need to uncomment the line that corresponds to the correct answer - you uncomment by removing the `#` symbol).\n",
    "\n",
    "* A. Wombat\n",
    "* B. Red panda.\n",
    "* C. Hyrax.\n",
    "* D. Meerkat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4781241f6df5e97c51b52d2bf1aaa0e1",
     "grade": false,
     "grade_id": "cell-b62ad6858d533e92",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def coolest_animal():\n",
    "    \"\"\"\n",
    "    This is a docstring. Docstrings are written in plain English\n",
    "    (they are not code), and are meant to help you remember\n",
    "    what your function does. In this case, this function\n",
    "    assigns a letter to the variable `answer`,\n",
    "    and then returns it. The letter corresponds\n",
    "    to the coolest animal in the world.\n",
    "    \n",
    "    Note: Hereinafter, we will be using the symbol ` to enclose words\n",
    "    that are variable names, like we just did with `answer`\n",
    "    \"\"\"\n",
    "    #answer = \"A\"\n",
    "    #answer = \"B\"\n",
    "    #answer = \"C\"\n",
    "    answer = \"D\"\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4ad90e9ede3e435a75cfc58cbb6cd508",
     "grade": false,
     "grade_id": "cell-cdaf9e90dc0957d0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "You can check that your function works by calling it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1fad42afaf1a9e6ddf32b93a81e300f3",
     "grade": false,
     "grade_id": "cell-99b714b4b205dd9b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coolest_animal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dbe6426d3f56aaa2fa6d9678e7211b03",
     "grade": false,
     "grade_id": "cell-c45b5856b685793b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Example 2\n",
    "\n",
    "Why did the chicken cross the road? (Remember, you need to uncomment the line that corresponds to the correct answer - you uncomment by removing the `#` symbol).\n",
    "\n",
    "* A. To attend an astrophysics conference.\n",
    "* B. To chat with a cool meerkat.\n",
    "* C. To get to the other side.\n",
    "* D. To have its hair done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c0f0482e07d2df186211bfc0e61e2dbb",
     "grade": false,
     "grade_id": "cell-449b9e0b2ec5c263",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def chicken_road():\n",
    "    \"\"\"\n",
    "    Assign a letter to the variable `answer`,\n",
    "    and then return it. The letter corresponds\n",
    "    to the reason why the chicken crossed the road.\n",
    "    \"\"\"\n",
    "    #answer = \"A\"\n",
    "    answer = \"B\"\n",
    "    #answer = \"C\"\n",
    "    #answer = \"D\"\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "85a831c85924ea70a33f35a955471f56",
     "grade": false,
     "grade_id": "cell-5637ea75803b2015",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "And checking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4b1f2b04c371cee1f0f473659bb2501b",
     "grade": false,
     "grade_id": "cell-bb5b3126fdfb1ae7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chicken_road()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1c7471138afdb09f794b7555eb40124b",
     "grade": false,
     "grade_id": "cell-bf707dad9c94ebb3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the questions below, you'll see a couple of lines that look like this:\n",
    "\n",
    "~~~python\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError() # Remove this line when you enter your solution\n",
    "~~~\n",
    "\n",
    "These lines are there to help us keep track of which exercises have been answered and which haven't. For the exercises in this review module, you should simply remove them and proceed to uncommenting the lines just as we explained above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "66189a139db7cc05043437d72dd4ca49",
     "grade": false,
     "grade_id": "cell-8223b04e63f90590",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Alright? Here come the questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "05a0fd532f1523d81a87bfea317fc9e0",
     "grade": false,
     "grade_id": "cell-02ef8633c00df18a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 1\n",
    "\n",
    "In computer science, Python is a(n)...\n",
    "\n",
    "* A. IDE\n",
    "* B. function\n",
    "* C. programming language\n",
    "* D. type of snake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "35962a3f579f8b0ce59fcc620df2bba1",
     "grade": false,
     "grade_id": "cell-19572b3e477e143f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def ex_1():\n",
    "    \"\"\"\n",
    "    Assign a letter to the variable `answer`,\n",
    "    and then return it.\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    \n",
    "    #answer = \"A\"\n",
    "    #answer = \"B\"\n",
    "    answer = \"C\"\n",
    "    #answer = \"D\"\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "232a4c468fd2f890dc98a45e51fe5c86",
     "grade": false,
     "grade_id": "cell-c2413532ab547040",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 2\n",
    "\n",
    "The 3 disciplines necessary to become a great data professional are...\n",
    "\n",
    "* A. Machine Learning, AI, Data Science\n",
    "\n",
    "* B. Math & Statistics, Computer Science, Business Expertise\n",
    "\n",
    "* C. Math & Statistics, Computer Programming, Data Science\n",
    "\n",
    "* D. Math & Statistics, Python, Business Expertise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d5a423c32a9a5779778d94aee4036553",
     "grade": false,
     "grade_id": "cell-9f31b59057e28bc8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def ex_2():\n",
    "    \"\"\"\n",
    "    Assign a letter to the variable `answer`,\n",
    "    and then return it.\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "#    answer = \"A\"\n",
    "    answer = \"B\"\n",
    "#     answer = \"C\"\n",
    "    #answer = \"D\"\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "07cefa9df71373c73fc61cbacc3cf5cb",
     "grade": false,
     "grade_id": "cell-4aa8d0dda883b125",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 3\n",
    "\n",
    "The `cd` command lets you...\n",
    "\n",
    "* A. Rename folders\n",
    "* B. See the contents of a folder\n",
    "* C. Create a new folder\n",
    "* D. Navigate around your computer's folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3d747831eb8c15b3e559e47663dce355",
     "grade": false,
     "grade_id": "cell-b34688694bf03284",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def ex_3():\n",
    "    \"\"\"\n",
    "    Assign a letter to the variable `answer`,\n",
    "    and then return it.\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    #answer = \"A\"\n",
    "    #answer = \"B\"\n",
    "    #answer = \"C\"\n",
    "    answer = \"D\"\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2eaa18b0877243cfc43f6f3610b92ed1",
     "grade": false,
     "grade_id": "cell-2f44a40996dc05cb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 4\n",
    "\n",
    "The `ls` command allows you to...\n",
    "\n",
    "* A. see the name of the current file\n",
    "* B. look into the contents of a file\n",
    "* C. see the contents of a folder\n",
    "* D. list the size of the current file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "20501b843ecfdf5c3f1c8765b96535a3",
     "grade": false,
     "grade_id": "cell-a7ef3f10e0b79b90",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def ex_4():\n",
    "    \"\"\"\n",
    "    Assign a letter to the variable `answer`,\n",
    "    and then return it.\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    #answer = \"A\"\n",
    "#     answer = \"B\"\n",
    "    answer = \"C\"\n",
    "    #answer = \"D\"\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "240db28956e0bd4542110e186aabe180",
     "grade": false,
     "grade_id": "cell-901fcede6611476f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Testing Cells\n",
    "\n",
    "Run the below cells to check your answers. Make sure you run your solution cells first before running the cells below, otherwise you will get a `NameError` when checking your answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bd6ab0c5f0e04501b92fa3435b8abb43",
     "grade": true,
     "grade_id": "cell-dfce3810f2c638eb",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercise 1 seems correct!\n"
     ]
    }
   ],
   "source": [
    "# Ex. 1\n",
    "assert ord(ex_1()) == 67, \"Ex. 1 - Think again! Check case 0.1 for a refresher!\"\n",
    "print(\"Exercise 1 seems correct!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "59ba718feebbead7e3e0e14d9e26d1a7",
     "grade": true,
     "grade_id": "cell-f0e6846c9b920e1e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercise 2 seems correct!\n"
     ]
    }
   ],
   "source": [
    "# Ex. 2\n",
    "assert ord(ex_2())*10 == 660, \"Ex. 2 - All these subjects are important, but which are the most important disciplines? See case 0.1 if you need a refresher!\"\n",
    "print(\"Exercise 2 seems correct!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d4a1d4a932997648084105cf0ba3f44f",
     "grade": true,
     "grade_id": "cell-71380078e8854049",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercise 3 seems correct!\n"
     ]
    }
   ],
   "source": [
    "# Ex. 3\n",
    "assert ord(ex_3())*11 == 748, \"Ex. 3 - This is the wrong answer. You can check the cd command's documentation - simply open your Jupyter terminal as explained in case 0.1 and type cd --help\"\n",
    "print(\"Exercise 3 seems correct!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aa18ce41ce0f3663623d6b54863afeaf",
     "grade": true,
     "grade_id": "cell-1c9d233c0f481434",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercise 4 seems correct!\n"
     ]
    }
   ],
   "source": [
    "# Ex. 4\n",
    "assert int(ex_4().encode('utf-8').hex()) == 43, \"Ex. 4 - This is the wrong answer. You can check the ls command's documentation - simply open your Jupyter terminal as explained in case 0.1 and type ls --help\"\n",
    "print(\"Exercise 4 seems correct!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
